{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b83dcba",
   "metadata": {},
   "source": [
    "# Logistic Regression (03/11/2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6da6a981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   monthly_charges  contract_duration_months  churn\n",
      "0        52.435729                        29      0\n",
      "1        44.527103                        22      1\n",
      "2        44.906903                        43      0\n",
      "3        39.200532                        12      1\n",
      "4        63.604767                        23      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data = {\n",
    "    'monthly_charges': np.random.normal(50, 20, 1000),\n",
    "    'contract_duration_months': np.random.randint(1, 48, 1000),\n",
    "    'churn': np.random.binomial(1, 0.4, 1000) # Baseline churn probability\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce a relationship to make the model meaningful\n",
    "df['churn'] = np.where(df['monthly_charges'] > 60, np.random.binomial(1, 0.6), df['churn'])\n",
    "df['churn'] = np.where(df['contract_duration_months'] > 24, np.random.binomial(1, 0.2), df['churn'])\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Define dependent and independent variables\n",
    "X = df[['monthly_charges', 'contract_duration_months']]\n",
    "y = df['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab445711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.296495\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  churn   No. Observations:                 1000\n",
      "Model:                          Logit   Df Residuals:                      997\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Mon, 03 Nov 2025   Pseudo R-squ.:                  0.2288\n",
      "Time:                        11:41:08   Log-Likelihood:                -296.49\n",
      "converged:                       True   LL-Null:                       -384.48\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.138e-39\n",
      "============================================================================================\n",
      "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                        1.9213      0.359      5.348      0.000       1.217       2.625\n",
      "monthly_charges             -0.0410      0.006     -6.595      0.000      -0.053      -0.029\n",
      "contract_duration_months    -0.1038      0.010    -10.000      0.000      -0.124      -0.083\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Add a constant for the intercept term\n",
    "X_const = sm.add_constant(X)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "logit_model = sm.Logit(y, X_const)\n",
    "logit_result = logit_model.fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(logit_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e75b7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Odds Ratios and 95% Confidence Intervals:\n",
      "                           Lower CI   Upper CI  Log-Odds Coeff\n",
      "const                     3.377624  13.811250        6.830022\n",
      "monthly_charges           0.948224   0.971606        0.959844\n",
      "contract_duration_months  0.883205   0.919900        0.901366\n"
     ]
    }
   ],
   "source": [
    "# Get the coefficients and confidence intervals from the results\n",
    "params = logit_result.params\n",
    "conf = logit_result.conf_int()\n",
    "conf['Odds Ratio'] = params\n",
    "conf.columns = ['Lower CI', 'Upper CI', 'Log-Odds Coeff']\n",
    "\n",
    "# Calculate the Odds Ratio and its 95% confidence interval\n",
    "odds_ratios = np.exp(conf)\n",
    "print(\"\\nOdds Ratios and 95% Confidence Intervals:\\n\", odds_ratios)\n",
    "\n",
    "# Interpretation\n",
    "# - Odds Ratio > 1: Increases the odds of the outcome.\n",
    "# - Odds Ratio < 1: Decreases the odds of the outcome.\n",
    "# - Odds Ratio = 1: No effect on the odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b7a49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hosmer-Lemeshow Test:\n",
      "  - Statistic: 19.0531\n",
      "  - P-value: 0.0146\n",
      "  - Conclusion: Model is a poor fit (Reject H0).\n"
     ]
    }
   ],
   "source": [
    "def hosmer_lemeshow_test(y_true, y_prob, bins=10):\n",
    "    \"\"\"\n",
    "    Performs the Hosmer-Lemeshow test.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'y_true': y_true, 'y_prob': y_prob})\n",
    "    df['decile'] = pd.qcut(df['y_prob'], bins, labels=False, duplicates='drop')\n",
    "\n",
    "    observed_events = df.groupby('decile')['y_true'].sum()\n",
    "    observed_non_events = df.groupby('decile')['y_true'].count() - observed_events\n",
    "    \n",
    "    expected_events = df.groupby('decile')['y_prob'].sum()\n",
    "    expected_non_events = df.groupby('decile')['y_prob'].count() - expected_events\n",
    "    \n",
    "    hl_statistic = np.sum(\n",
    "        (observed_events - expected_events)**2 / expected_events +\n",
    "        (observed_non_events - expected_non_events)**2 / expected_non_events\n",
    "    )\n",
    "    \n",
    "    # Degrees of freedom is (number of bins - 2)\n",
    "    degrees_of_freedom = len(observed_events) - 2\n",
    "    \n",
    "    # Get p-value from chi-squared distribution\n",
    "    from scipy.stats import chi2\n",
    "    p_value = 1 - chi2.cdf(hl_statistic, degrees_of_freedom)\n",
    "\n",
    "    return hl_statistic, p_value\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_prob = logit_result.predict(X_const)\n",
    "\n",
    "# Perform the Hosmer-Lemeshow test\n",
    "hl_statistic, hl_p_value = hosmer_lemeshow_test(y, y_prob)\n",
    "\n",
    "print(f\"\\nHosmer-Lemeshow Test:\")\n",
    "print(f\"  - Statistic: {hl_statistic:.4f}\")\n",
    "print(f\"  - P-value: {hl_p_value:.4f}\")\n",
    "if hl_p_value > 0.05:\n",
    "    print(\"  - Conclusion: Model is a good fit (Fail to reject H0).\")\n",
    "else:\n",
    "    print(\"  - Conclusion: Model is a poor fit (Reject H0).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e37178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concordance (C-statistic/AUC): 0.8398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate the concordance (C-statistic)\n",
    "c_statistic = roc_auc_score(y, y_prob)\n",
    "print(f\"\\nConcordance (C-statistic/AUC): {c_statistic:.4f}\")\n",
    "\n",
    "# Interpretation of C-statistic\n",
    "# - 0.5: No better than random chance.\n",
    "# - >0.7: Considered a good model.\n",
    "# - >0.8: Considered a strong model.\n",
    "# - 1.0: Perfect discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7f0575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rank Ordering (Decile Analysis):\n",
      "                         total_customers  events  event_rate\n",
      "Decile (1=Highest Prob)                                     \n",
      "0                                    100       0        0.00\n",
      "1                                    100       0        0.00\n",
      "2                                    100       0        0.00\n",
      "3                                    100       0        0.00\n",
      "4                                    100       4        0.04\n",
      "5                                    100      11        0.11\n",
      "6                                    100      20        0.20\n",
      "7                                    100      26        0.26\n",
      "8                                    100      27        0.27\n",
      "9                                    100      41        0.41\n"
     ]
    }
   ],
   "source": [
    "# Combine actuals and predicted probabilities\n",
    "analysis_df = pd.DataFrame({'actuals': y, 'predicted_prob': y_prob})\n",
    "\n",
    "# Create decile groups based on predicted probabilities\n",
    "analysis_df['decile'] = pd.qcut(analysis_df['predicted_prob'], 10, labels=False, duplicates='drop')\n",
    "analysis_df = analysis_df.sort_values('decile', ascending=False)\n",
    "\n",
    "# Calculate the event rate per decile\n",
    "rank_ordering_df = analysis_df.groupby('decile').agg(\n",
    "    total_customers=('actuals', 'count'),\n",
    "    events=('actuals', 'sum')\n",
    ")\n",
    "rank_ordering_df['event_rate'] = rank_ordering_df['events'] / rank_ordering_df['total_customers']\n",
    "rank_ordering_df.index.name = 'Decile (1=Highest Prob)'\n",
    "print(\"\\nRank Ordering (Decile Analysis):\")\n",
    "print(rank_ordering_df)\n",
    "\n",
    "# Interpretation\n",
    "# - The `event_rate` should generally decrease from Decile 1 (highest probability) to Decile 10 (lowest probability).\n",
    "# - A consistent decrease indicates good rank ordering, confirming the model effectively segments customers based on their likelihood of churning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0575e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KS Statistic: 0.5674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rashmi\\AppData\\Local\\Temp\\ipykernel_2856\\3894431375.py:17: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_merged = df_merged.fillna(method='ffill').fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "def ks_statistic(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Calculates the Kolmogorov-Smirnov statistic.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'y_true': y_true, 'y_prob': y_prob})\n",
    "    \n",
    "    # Separate events (1s) and non-events (0s)\n",
    "    df_event = df[df['y_true'] == 1].sort_values('y_prob', ascending=True)\n",
    "    df_non_event = df[df['y_true'] == 0].sort_values('y_prob', ascending=True)\n",
    "    \n",
    "    # Calculate cumulative distributions\n",
    "    cdf_event = np.linspace(1/len(df_event), 1, len(df_event))\n",
    "    cdf_non_event = np.linspace(1/len(df_non_event), 1, len(df_non_event))\n",
    "    \n",
    "    # Merge on probability and fill NaNs\n",
    "    df_merged = pd.merge_asof(df_non_event, df_event, on='y_prob', direction='nearest')\n",
    "    df_merged = df_merged.fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    # Interpolate to find cumulative probabilities at matching points\n",
    "    merged_cdf_event = np.interp(df_non_event['y_prob'], df_event['y_prob'], cdf_event)\n",
    "    \n",
    "    # Calculate the maximum difference\n",
    "    max_diff = np.max(np.abs(cdf_non_event - merged_cdf_event))\n",
    "    \n",
    "    return max_diff\n",
    "\n",
    "# Calculate the KS statistic\n",
    "ks_val = ks_statistic(y, y_prob)\n",
    "print(f\"\\nKS Statistic: {ks_val:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
